{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7079553435838845\n",
      "Epoch 10, Loss: 0.7074932441847918\n",
      "Epoch 20, Loss: 0.70703612591019\n",
      "Epoch 30, Loss: 0.7065839332715019\n",
      "Epoch 40, Loss: 0.7061366111747969\n",
      "Epoch 50, Loss: 0.7056941049190038\n",
      "Epoch 60, Loss: 0.7052563601942042\n",
      "Epoch 70, Loss: 0.7048233230800026\n",
      "Epoch 80, Loss: 0.7043949400439674\n",
      "Epoch 90, Loss: 0.7039711579401454\n",
      "Predictions: [[0.58493576 0.57780582 0.59472959 0.61442552 0.60632751 0.62949297\n",
      "  0.59138677 0.57444345 0.59723655 0.57510056]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class FFNN:\n",
    "    def __init__(self, layers, activations, weight_init='random_uniform', seed=None):\n",
    "        np.random.seed(seed)\n",
    "        self.layers = layers\n",
    "        self.activations = activations\n",
    "        self.weights = []\n",
    "        self.biases = []\n",
    "        self.initialize_weights(weight_init, seed)\n",
    "    \n",
    "    def initialize_weights(self, method, seed):\n",
    "        for i in range(len(self.layers) - 1):\n",
    "            input_size = self.layers[i]\n",
    "            output_size = self.layers[i + 1]\n",
    "            if method == 'zero':\n",
    "                W = np.zeros((output_size, input_size))\n",
    "                b = np.zeros((output_size, 1))\n",
    "            elif method == 'random_uniform':\n",
    "                W = np.random.uniform(-1, 1, (output_size, input_size))\n",
    "                b = np.random.uniform(-1, 1, (output_size, 1))\n",
    "            elif method == 'random_normal':\n",
    "                W = np.random.randn(output_size, input_size)\n",
    "                b = np.random.randn(output_size, 1)\n",
    "            self.weights.append(W)\n",
    "            self.biases.append(b)\n",
    "    \n",
    "    def activation_function(self, x, func):\n",
    "        if func == 'linear':\n",
    "            return x\n",
    "        elif func == 'relu':\n",
    "            return np.maximum(0, x)\n",
    "        elif func == 'sigmoid':\n",
    "            return 1 / (1 + np.exp(-x))\n",
    "        elif func == 'tanh':\n",
    "            return np.tanh(x)\n",
    "        elif func == 'softmax':\n",
    "            exp_x = np.exp(x - np.max(x, axis=0, keepdims=True))\n",
    "            return exp_x / np.sum(exp_x, axis=0, keepdims=True)\n",
    "    \n",
    "    def activation_derivative(self, x, func):\n",
    "        if func == 'linear':\n",
    "            return np.ones_like(x)\n",
    "        elif func == 'relu':\n",
    "            return (x > 0).astype(float)\n",
    "        elif func == 'sigmoid':\n",
    "            sig = self.activation_function(x, 'sigmoid')\n",
    "            return sig * (1 - sig)\n",
    "        elif func == 'tanh':\n",
    "            return 1 - np.tanh(x) ** 2\n",
    "        elif func == 'softmax':\n",
    "            return x * (1 - x)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        activations = []\n",
    "        inputs = X\n",
    "        for W, b, func in zip(self.weights, self.biases, self.activations):\n",
    "            Z = np.dot(W, inputs) + b\n",
    "            inputs = self.activation_function(Z, func)\n",
    "            activations.append(inputs)\n",
    "        return activations\n",
    "    \n",
    "    def compute_loss(self, Y_pred, Y_true, loss_function):\n",
    "        if loss_function == 'mse':\n",
    "            return np.mean((Y_pred - Y_true) ** 2)\n",
    "        elif loss_function == 'binary_cross_entropy':\n",
    "            return -np.mean(Y_true * np.log(Y_pred + 1e-9) + (1 - Y_true) * np.log(1 - Y_pred + 1e-9))\n",
    "        elif loss_function == 'categorical_cross_entropy':\n",
    "            return -np.sum(Y_true * np.log(Y_pred + 1e-9)) / Y_true.shape[1]\n",
    "    \n",
    "    def backward(self, X, Y_true, learning_rate, loss_function):\n",
    "        activations = self.forward(X)\n",
    "        grads_W = []\n",
    "        grads_b = []\n",
    "        Y_pred = activations[-1]\n",
    "        \n",
    "        dA = Y_pred - Y_true if loss_function == 'mse' else (Y_pred - Y_true) / Y_true.shape[1]\n",
    "        \n",
    "        for i in reversed(range(len(self.weights))):\n",
    "            dZ = dA * self.activation_derivative(activations[i], self.activations[i])\n",
    "            dW = np.dot(dZ, activations[i-1].T) if i > 0 else np.dot(dZ, X.T)\n",
    "            db = np.sum(dZ, axis=1, keepdims=True)\n",
    "            \n",
    "            grads_W.insert(0, dW)\n",
    "            grads_b.insert(0, db)\n",
    "            dA = np.dot(self.weights[i].T, dZ)\n",
    "            \n",
    "            self.weights[i] -= learning_rate * dW\n",
    "            self.biases[i] -= learning_rate * db\n",
    "    \n",
    "    def train(self, X, Y, epochs, learning_rate, loss_function):\n",
    "        for epoch in range(epochs):\n",
    "            self.backward(X, Y, learning_rate, loss_function)\n",
    "            if epoch % 10 == 0:\n",
    "                loss = self.compute_loss(self.forward(X)[-1], Y, loss_function)\n",
    "                print(f'Epoch {epoch}, Loss: {loss}')\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.forward(X)[-1]\n",
    "\n",
    "# Contoh penggunaan\n",
    "if __name__ == \"__main__\":\n",
    "    X_train = np.random.rand(3, 10)  # 3 input neurons, 10 samples\n",
    "    Y_train = np.random.randint(0, 2, (1, 10))  # Binary classification\n",
    "    \n",
    "    ffnn = FFNN(layers=[3, 5, 1], activations=['relu', 'sigmoid'], weight_init='random_uniform', seed=42)\n",
    "    ffnn.train(X_train, Y_train, epochs=100, learning_rate=0.01, loss_function='binary_cross_entropy')\n",
    "    \n",
    "    print(\"Predictions:\", ffnn.predict(X_train))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
